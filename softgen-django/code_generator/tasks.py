from celery import shared_task
from .models import Software
from django.conf import settings
from .services.openai import openai_client
from .services.github import upload_software_to_github
from .serializers import FileSerializer
import time
from .utils import process_file_list, check_already_generated, json_load_message

@shared_task
def test_celery_task(software_id):
    # Simula uma operação de longa duração
    time.sleep(10)  # Espera 10 segundos

    # Atualiza um campo no modelo Software
    software = Software.objects.get(pk=software_id)
    software.llm_thread_id = "Task completed"
    software.save()

@shared_task
def create_files_task(software_id):
    software = Software.objects.get(pk=software_id)
    thread_id = None #settings.THREAD_ID
    failed_files = []

    assistant = openai_client.assistant(settings.ASSISTANT_ID)
    assistant.send_message(
        prompt=software.processed_specs,
        thread_id=thread_id
    )

    # Update software with LLM info
    software.llm_assistant_id = assistant.get_assistant_id()
    software.llm_thread_id = assistant.get_thread_id()
    software.save()

    # Wait OpenAI run
    messages = assistant.wait_for_run_completion()
    print(messages)
    
    analysis = check_already_generated(messages)
    # analysis = {'framework': 'Django', 
    #             'failed': False, 
    #             'generated': [{'file': '...', 'instructions': '...', 'content': '...'}, ..., {'file': '...', 'instructions': '...', 'content': '...'}], 
    #             'files': ['file_1', ..., 'file_n']}
    
    if analysis['failed']:
        software.delete()
        raise ValueError(f"Generation request failed:\n{analysis}\n\n{messages}")
    
    file_list = process_file_list(analysis['files'])
    print(f'Filtered file list: {file_list}')
    generated_files = [msg['file'] for msg in analysis['generated']]

    for file_path in file_list:
        if file_path not in generated_files:
            assistant.send_message(
                prompt=f'Generate the content for: {file_path}',
                thread_id=thread_id
            )
            # Wait OpenAI run
            messages = assistant.wait_for_run_completion()
            response = json_load_message(messages.data[0].content[0].text.value)
        else:
            print(f'File already generated by LLM: {file_path}')
            response =  [msg for msg in analysis['generated'] if msg['file'] == file_path][0]
        #print(f'Content for {file_path}: \n{response}\n')
        file_content = response.get('content')
        if file_content is None:
            print(f'(SKIPPING) Null Content for {file_path}: \n{response}\n')
            continue

        try:
            instructions = response.get('instructions')[:72]
        except:
            instructions = ""

        file = {'software': software.id,
                'path': file_path,
                'version': 1,
                'content': file_content,
                'instructions': instructions}
        serializer = FileSerializer(data=file)
        if serializer.is_valid():
            serializer.save()
        else:
            print(serializer.errors)
            failed_files.append({'file':file_path, 'llm_response': response})
    
    software.generation_finished = True
    software.save()

    if failed_files:
        print(f'Erros na criação ({len(failed_files)}/{len(file_list)}): {failed_files}')
    else:
        print(f'Code generated successfully.')
        upload_software_to_github(software_id)
